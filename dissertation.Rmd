---
title: "Interfacing R with Web Technologies for Data Acquistion and Interactive Visualization"
author: "Carson Sievert"
date: '`r Sys.Date()`'
documentclass: book
bibliography: references.bib
biblio-style: apalike
link-citations: yes
site: bookdown::bookdown_site
description: "An overview of the R package plotly"
url: 'http://cpsievert.github.io/phd-thesis'
github-repo: cpsievert/phd-thesis
---

```{r}
knitr::opts_chunk$set(
  fig.height = 6,
  fig.asp = 0.618,
  comment = "#>",
  collapse = TRUE,
  warning = FALSE,
  message = FALSE
)
```

# Abstract {-}

The following describes a collection of software interfaces for data acquisiton and visualization. All of these interfaces are freely available as extension packages to the R language and leverage web technologies to achieve accessible, portable, and reproducible workflows. The majority of this work (`LDAvis`, `animint`, and `plotly`) focuses on interactive visualization. These interfaces fall roughly into two categories: (1) domain-specific (`LDAvis`) and (2) general purpose visualization (`animint` and `plotly`). More specifially, the `LDAvis` package produces an interactive visualization to aid interpretation of Latent Dirichlet Allocation (LDA) model output. The `animint` and `plotly` packages are more general, and build upon principles from the grammar of graphics [@Wilkinson:2005], but extend those principles in slightly different ways to enable interactivity, such as brushing a scatterplot matrix [@brushing-scatterplots]. 

## What makes a good software interface?

Unwin and Hofmann [@Unwin:1999vp] discuss the strengths, weaknesses, and differences between using graphical and command-line interfaces for data analysis. Graphical user interfaces (GUIs) can be much more intuitive to use, but at the cost of being less flexible, precise, and repeatable. Unwin and Hofmann argue statistical software should strive to achieve a synergy of two that leverages both of their strengths. That is, a command-line interface when we can precisely describe what we want and a graphical interface for "searching for information and interesting structures without fully specified questions."

Unwin and Hofmann further discuss the different audiences these interfaces attract. Command-line interfaces typically attract "power users" such as applied statisticians and statistical researchers in a university, whereas more casual users of statistical software typically prefer a GUI. In later sections, we discuss GUIs in greater detail within the context of interactive statistical graphics. For now, we briefly discuss some best practices for designing a command-line interface for statistical computing in R.

Before authoring an interface, one should establish the target audience, the class of problems it should address, and loosely define how the interface should actually work. During this process, it may also be helpful to identify your audience as being primarily composed of _software developers_ or _data analysts_. Developers are typically more interested in using the interface to develop novel software or incorporating the functionality into a larger scientific computing environment [@embedded-computing]. In this case, interactive exploration and troubleshooting is not always a luxury, so robust functionality is of utmost importance. On the other hand, analysts interfaces should work well in an interactive environment since this caters to rapid prototyping of ideas and troubleshooting of errors.

Good developer interfaces often make it easier to implement good analyst interfaces. A great recent example of a good developer interface is the R package __Rcpp__, which provides a seamless interface between R with C++ [@Rcpp]. To date, more than 500 R packages use __Rcpp__ to make interfaces that are both expressive and efficient, including the highly influential analyst interfaces such as __tidyr__ and __dplyr__ [@tidy-data]; [@dplyr]. These interfaces help analysts focus on the primary task of wrangling data into a form suitable for visualization and statistical modeling, rather than focusing on the implementation details behind how the transformations are performed. [@Donoho:2015tu] argues that these interfaces "May have more impact on todayâ€™s practice of data analysis than many highly-regarded theoretical statistics papers".

<!--
 TODO:
* Difficulty in evaluating interfaces?
* Purely functional programming?
* Compatible interfaces (S3)?
-->

Evaluating statistical computing interfaces is certainly a subjective matter since we all have different tastes, different backgrounds, and have different needs. It seems reasonable to evaluate an interface based on its effectiveness and efficiency in aiding a user complete their task, but as [@Unwin:1999vp] points out, "There is a tendency to judge software by the most powerful tools they provide (whether with a good interface or not)". As a result, all too often, analysts must spend time gaining the skills of a software developer. Good analyst interfaces often abstract functionality from developer interfaces in a way that allow analysts to focus on their primary task of acquiring/analyzing/modeling/visualizing data, rather than the implementation details. The following focuses on such work with respect to acquiring data from the web and interactive statistical web graphics. 

<!-- TODO
* More motivation via Bill Cleveland's Tool Evaluation?
http://www.stat.purdue.edu/~wsc/papers/datascience.pdf
-->
